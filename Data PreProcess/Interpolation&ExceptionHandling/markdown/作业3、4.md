
# 数据预处理-2

- 班级:2017211314
- 学号:2017213508
- 学生:蒋雪枫

## 作业3

**一些额外的Trick:**
- 比如想要产生新的一列来统计同一时间内所有地方的PM指数和
df['sumOfPM']=df['PM_US_POST']+df['PM_Nongzhanguan']+df['PM_Dongsi']+df['PM_Dongsihuan']
- 比如想要按照某一列排序,升序
def top(df,n=5,colunm='PRES'):
    return df.sort_values(by=column)[-n:]
- apply函数是`pandas`里面所有函数中自由度最高的函数。该函数如下：
DataFrame.apply(func, axis=0, broadcast=False, raw=False...)
该函数最有用的是第一个参数，这个参数是函数，相当于C/C++的函数指针。

- 这次预处理实验和上次预处理实验后,我明显感受到直接按列操作比遍历每一个csv中的cell效率高得多,减小了IO时间


```python
import numpy as np
import pandas as pd
import time
import matplotlib.pyplot as plt

df = pd.read_csv("BeijingPM20100101_20151231.csv",encoding='utf-8')
df.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>No</th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>hour</th>
      <th>season</th>
      <th>PM_Dongsi</th>
      <th>PM_Dongsihuan</th>
      <th>PM_Nongzhanguan</th>
      <th>PM_US Post</th>
      <th>DEWP</th>
      <th>HUMI</th>
      <th>PRES</th>
      <th>TEMP</th>
      <th>Iws</th>
      <th>precipitation</th>
      <th>Iprec</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>52584.000000</td>
      <td>52584.000000</td>
      <td>52584.000000</td>
      <td>52584.000000</td>
      <td>52584.000000</td>
      <td>52584.000000</td>
      <td>25052.000000</td>
      <td>20508.000000</td>
      <td>24931.000000</td>
      <td>50387.000000</td>
      <td>52579.000000</td>
      <td>52245.000000</td>
      <td>52245.000000</td>
      <td>52579.000000</td>
      <td>52579.000000</td>
      <td>52100.000000</td>
      <td>52100.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>26292.500000</td>
      <td>2012.499772</td>
      <td>6.523962</td>
      <td>15.726609</td>
      <td>11.500000</td>
      <td>2.491100</td>
      <td>89.154439</td>
      <td>92.560806</td>
      <td>88.643737</td>
      <td>95.904241</td>
      <td>2.074554</td>
      <td>54.602421</td>
      <td>1016.465442</td>
      <td>12.587040</td>
      <td>23.261829</td>
      <td>19.258683</td>
      <td>19.519008</td>
    </tr>
    <tr>
      <th>std</th>
      <td>15179.837614</td>
      <td>1.707485</td>
      <td>3.448452</td>
      <td>8.798896</td>
      <td>6.922252</td>
      <td>1.116988</td>
      <td>87.239267</td>
      <td>88.027434</td>
      <td>88.041166</td>
      <td>91.643772</td>
      <td>14.222059</td>
      <td>25.991338</td>
      <td>10.295070</td>
      <td>12.098527</td>
      <td>49.281706</td>
      <td>4381.035532</td>
      <td>4381.036040</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>2010.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>-40.000000</td>
      <td>2.000000</td>
      <td>991.000000</td>
      <td>-19.000000</td>
      <td>0.450000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>13146.750000</td>
      <td>2011.000000</td>
      <td>4.000000</td>
      <td>8.000000</td>
      <td>5.750000</td>
      <td>1.000000</td>
      <td>24.000000</td>
      <td>28.000000</td>
      <td>24.000000</td>
      <td>27.000000</td>
      <td>-10.000000</td>
      <td>31.000000</td>
      <td>1008.000000</td>
      <td>2.000000</td>
      <td>1.790000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>26292.500000</td>
      <td>2012.000000</td>
      <td>7.000000</td>
      <td>16.000000</td>
      <td>11.500000</td>
      <td>2.000000</td>
      <td>64.000000</td>
      <td>68.000000</td>
      <td>62.000000</td>
      <td>69.000000</td>
      <td>2.000000</td>
      <td>55.000000</td>
      <td>1016.000000</td>
      <td>14.000000</td>
      <td>4.920000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>39438.250000</td>
      <td>2014.000000</td>
      <td>10.000000</td>
      <td>23.000000</td>
      <td>17.250000</td>
      <td>3.000000</td>
      <td>124.000000</td>
      <td>127.000000</td>
      <td>122.000000</td>
      <td>132.000000</td>
      <td>15.000000</td>
      <td>78.000000</td>
      <td>1025.000000</td>
      <td>23.000000</td>
      <td>21.020000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>52584.000000</td>
      <td>2015.000000</td>
      <td>12.000000</td>
      <td>31.000000</td>
      <td>23.000000</td>
      <td>4.000000</td>
      <td>737.000000</td>
      <td>672.000000</td>
      <td>844.000000</td>
      <td>994.000000</td>
      <td>28.000000</td>
      <td>100.000000</td>
      <td>1046.000000</td>
      <td>42.000000</td>
      <td>585.600000</td>
      <td>999990.000000</td>
      <td>999990.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
todo = ['HUMI', 'PRES', 'TEMP']
#进行线性插值
for each in todo:
    df[each]=df[each].interpolate(method="linear")
print("将dataframe其中一列抽出来是什么类型?{}".format(type(df['HUMI'])))
for each in todo:
    mean = df[each].mean()
    stdDoub = df[each].std()
    df[each]= df[each].apply(lambda x : mean + stdDoub*2 if x>mean + stdDoub * 2 
                                  else ( mean-2 * stdDoub if x < mean -  2 * stdDoub else x))

```

    将dataframe其中一列抽出来是什么类型?<class 'pandas.core.series.Series'>
    


```python
todo = ['PM_Dongsi','PM_Dongsihuan','PM_Nongzhanguan']
print("处理前")
#   PM:6,7,8,9 || HUMI PRES TEMP:11,12,13 || cbwd:14
print(df.iloc[30590:30600,6:9])
for each in todo:
    df[each] = df[each].apply(lambda x: 500 if x > 500 else x)
print("处理后")
print(df.iloc[30590:30600,6:9])
```

    处理前
           PM_Dongsi  PM_Dongsihuan  PM_Nongzhanguan
    30590      287.0          443.0            326.0
    30591      495.0          508.0            512.0
    30592      495.0          513.0            513.0
    30593      485.0          513.0            501.0
    30594      515.0          537.0            530.0
    30595      507.0          505.0            508.0
    30596      487.0          443.0            475.0
    30597      345.0          351.0            357.0
    30598       34.0           39.0             28.0
    30599       30.0           40.0             24.0
    处理后
           PM_Dongsi  PM_Dongsihuan  PM_Nongzhanguan
    30590      287.0          443.0            326.0
    30591      495.0          500.0            500.0
    30592      495.0          500.0            500.0
    30593      485.0          500.0            500.0
    30594      500.0          500.0            500.0
    30595      500.0          500.0            500.0
    30596      487.0          443.0            475.0
    30597      345.0          351.0            357.0
    30598       34.0           39.0             28.0
    30599       30.0           40.0             24.0
    


```python
#下面第一种方式比较直观,但如果出现两个连续的cv,怎么处理?  
# Excel里面也告诉我们的确出现了
# for i in range(len(df['cbwd'])):
#     if df['cbwd'][i] == 'cv':
#         df.at[i:i,'cbwd'] =  df['cbwd'][i+1]
print("对CV处理前")
print(df.iloc[20:25,8:15])
print("对CV处理后")
#TODO:采用bfill替换方式
df['cbwd']=df['cbwd'].replace('cv',method='bfill')
print(df.iloc[20:25,8:15])
```

    对CV处理前
        PM_Nongzhanguan  PM_US Post  DEWP  HUMI    PRES  TEMP cbwd
    20              NaN         NaN -17.0  38.0  1017.0  -5.0   cv
    21              NaN         NaN -17.0  38.0  1018.0  -5.0   NW
    22              NaN         NaN -17.0  38.0  1018.0  -5.0   NW
    23              NaN       129.0 -17.0  41.0  1020.0  -5.0   cv
    24              NaN       148.0 -16.0  38.0  1020.0  -4.0   SE
    对CV处理后
        PM_Nongzhanguan  PM_US Post  DEWP  HUMI    PRES  TEMP cbwd
    20              NaN         NaN -17.0  38.0  1017.0  -5.0   NW
    21              NaN         NaN -17.0  38.0  1018.0  -5.0   NW
    22              NaN         NaN -17.0  38.0  1018.0  -5.0   NW
    23              NaN       129.0 -17.0  41.0  1020.0  -5.0   SE
    24              NaN       148.0 -16.0  38.0  1020.0  -4.0   SE
    


```python
df.describe() 
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>No</th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>hour</th>
      <th>season</th>
      <th>PM_Dongsi</th>
      <th>PM_Dongsihuan</th>
      <th>PM_Nongzhanguan</th>
      <th>PM_US Post</th>
      <th>DEWP</th>
      <th>HUMI</th>
      <th>PRES</th>
      <th>TEMP</th>
      <th>Iws</th>
      <th>precipitation</th>
      <th>Iprec</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>52584.000000</td>
      <td>52584.000000</td>
      <td>52584.000000</td>
      <td>52584.000000</td>
      <td>52584.000000</td>
      <td>52584.000000</td>
      <td>25052.000000</td>
      <td>20508.000000</td>
      <td>24931.000000</td>
      <td>50387.000000</td>
      <td>52579.000000</td>
      <td>52584.000000</td>
      <td>52584.000000</td>
      <td>52584.000000</td>
      <td>52579.000000</td>
      <td>52100.000000</td>
      <td>52100.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>26292.500000</td>
      <td>2012.499772</td>
      <td>6.523962</td>
      <td>15.726609</td>
      <td>11.500000</td>
      <td>2.491100</td>
      <td>88.909788</td>
      <td>92.373464</td>
      <td>88.409570</td>
      <td>95.904241</td>
      <td>2.074554</td>
      <td>54.851158</td>
      <td>1016.517506</td>
      <td>12.599689</td>
      <td>23.261829</td>
      <td>19.258683</td>
      <td>19.519008</td>
    </tr>
    <tr>
      <th>std</th>
      <td>15179.837614</td>
      <td>1.707485</td>
      <td>3.448452</td>
      <td>8.798896</td>
      <td>6.922252</td>
      <td>1.116988</td>
      <td>85.898308</td>
      <td>87.056715</td>
      <td>86.760055</td>
      <td>91.643772</td>
      <td>14.222059</td>
      <td>26.095084</td>
      <td>10.224785</td>
      <td>12.063515</td>
      <td>49.281706</td>
      <td>4381.035532</td>
      <td>4381.036040</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>2010.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>-40.000000</td>
      <td>2.660485</td>
      <td>995.931255</td>
      <td>-11.609537</td>
      <td>0.450000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>13146.750000</td>
      <td>2011.000000</td>
      <td>4.000000</td>
      <td>8.000000</td>
      <td>5.750000</td>
      <td>1.000000</td>
      <td>24.000000</td>
      <td>28.000000</td>
      <td>24.000000</td>
      <td>27.000000</td>
      <td>-10.000000</td>
      <td>32.000000</td>
      <td>1008.000000</td>
      <td>2.000000</td>
      <td>1.790000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>26292.500000</td>
      <td>2012.000000</td>
      <td>7.000000</td>
      <td>16.000000</td>
      <td>11.500000</td>
      <td>2.000000</td>
      <td>64.000000</td>
      <td>68.000000</td>
      <td>62.000000</td>
      <td>69.000000</td>
      <td>2.000000</td>
      <td>55.000000</td>
      <td>1016.000000</td>
      <td>14.000000</td>
      <td>4.920000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>39438.250000</td>
      <td>2014.000000</td>
      <td>10.000000</td>
      <td>23.000000</td>
      <td>17.250000</td>
      <td>3.000000</td>
      <td>124.000000</td>
      <td>127.000000</td>
      <td>122.000000</td>
      <td>132.000000</td>
      <td>15.000000</td>
      <td>78.000000</td>
      <td>1025.000000</td>
      <td>23.000000</td>
      <td>21.020000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>52584.000000</td>
      <td>2015.000000</td>
      <td>12.000000</td>
      <td>31.000000</td>
      <td>23.000000</td>
      <td>4.000000</td>
      <td>500.000000</td>
      <td>500.000000</td>
      <td>500.000000</td>
      <td>994.000000</td>
      <td>28.000000</td>
      <td>100.000000</td>
      <td>1037.147438</td>
      <td>36.783754</td>
      <td>585.600000</td>
      <td>999990.000000</td>
      <td>999990.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
df.to_csv("result.csv")
```

**比较前后的描述信息,可以较为明显地看出有关标准差采取的措施带来的改变**

## 作业4


```python
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
features = ['DEWP', 'TEMP']
df[features] = scaler.fit_transform(df[features])
df.head()
df.plot.scatter(x=['DEWP'],y=['TEMP'],s=10,figsize = (20,20))
```




    <matplotlib.axes._subplots.AxesSubplot at 0x1e91b7291d0>




![png](output_10_1.png)



```python
from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
features = ['DEWP', 'TEMP']
df[features] = ss.fit_transform(df[features])
df.head()
df.plot.scatter(x=['DEWP'],y=['TEMP'],s=10,figsize = (20,20))
```




    <matplotlib.axes._subplots.AxesSubplot at 0x1e918f71ef0>




![png](output_11_1.png)



```python
sections = [0,50,100,150,200,300,1200] #划分为不同长度 的区间 
section_names=["green","yellow","orange","red","purple", "Brownish red"] #设置每个区间的标签
# df = df.fillna(df.mean())
result = pd.cut(df.PM_Dongsi,sections,labels=section_names) 
print(pd.value_counts(result))
```

    green           10576
    yellow           6268
    orange           3578
    red              1942
    purple           1910
    Brownish red      778
    Name: PM_Dongsi, dtype: int64
    
